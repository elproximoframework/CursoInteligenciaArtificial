<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Presentación: Deep Learning</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Montserrat:wght@600;700;800&display=swap" rel="stylesheet">
    <style>
        
        body, html { 
            margin: 0; 
            padding: 0; 
            background-color: #0c1421;
            height: 100%;
        }
        .main-view {
            display: flex;
            height: 100vh;
        }
        .presentation-wrapper {
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }
        #script-panel {
            width: 450px;
            flex-shrink: 0;
            background-color: #080f1a;
            color: #e5e7eb;
            border-left: 1px solid #1f2937;
            overflow-y: auto;
            padding: 2rem;
            font-family: 'Roboto', sans-serif;
        }
        #script-panel h2 {
            font-family: 'Montserrat', sans-serif;
            font-weight: 700;
            color: #67e8f9; /* cyan-300 */
            font-size: 1.5rem; /* text-2xl */
            margin-bottom: 1rem;
        }
        #script-panel h3 {
            font-family: 'Montserrat', sans-serif;
            font-weight: 600;
            color: #fde047; /* amber-300 */
            font-size: 1.125rem; /* text-lg */
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
        }
        #script-panel p {
            line-height: 1.625;
            color: #d1d5db; /* gray-300 */
            margin-bottom: 1rem;
        }
        .presentation-wrapper {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 100vw;
            height: 100vh;
        }
        .slide {
            display: none;
            width: 1280px; 
            min-height: 720px; 
            position: relative;
            font-family: 'Roboto', sans-serif; 
            color: white;
            overflow: hidden;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 4rem;
            background: linear-gradient(135deg, #1c0537, #4a007a, #870093);
        }
        .slide.active {
            display: flex;
        }

        .title { font-family: 'Montserrat', sans-serif; font-weight: 800; letter-spacing: -1px; text-shadow: 0 2px 10px rgba(0,0,0,0.3); }
        .subtitle { font-family: 'Montserrat', sans-serif; font-weight: 600; }
        .content-box { background-color: rgba(255, 255, 255, 0.1); backdrop-filter: blur(5px); border: 1px solid rgba(255, 255, 255, 0.2); }
        .stars {
            position: absolute; width: 100%; height: 100%; top: 0; left: 0; z-index: -1;
            background-image: radial-gradient(white, rgba(255, 255, 255, 0.2) 2px, transparent 2px);
            background-size: 200px 200px; opacity: 0.08;
            animation: stars-move 80s linear infinite;
        }
        @keyframes stars-move {
            from { background-position: 0 0; }
            to { background-position: -2000px -2000px; }
        }
        .footer-note {
            position: absolute; bottom: 1rem; right: 2rem; text-align: right;
            font-size: 0.875rem; color: #d8b4fe; z-index: 10;
        }
        #navigation-controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(0, 0, 0, 0.4);
            backdrop-filter: blur(5px);
            border-radius: 20px;
            padding: 8px 15px;
            display: flex;
            align-items: center;
            gap: 20px;
            z-index: 100;
        }
        #navigation-controls button {
            background: none;
            border: none;
            color: white;
            font-size: 24px;
            cursor: pointer;
            transition: color 0.2s, transform 0.2s;
        }
        #navigation-controls button:hover:not(:disabled) { color: #c4b5fd; transform: scale(1.1); }
        #navigation-controls button:disabled { color: #4b5563; cursor: not-allowed; }
        #slide-counter { color: white; font-family: 'Montserrat', sans-serif; font-weight: 600; font-size: 16px; }

        /* --- ANIMACIONES GENERALES --- */
        .active .fade-in-up { animation: fade-in-up-anim 0.8s ease-out forwards; opacity: 0; }
        @keyframes fade-in-up-anim { from { opacity: 0; transform: translateY(20px); } to { opacity: 1; transform: translateY(0); } }
        .active .fade-in { animation: fade-in-anim 1s ease-in forwards; opacity: 0; }
        @keyframes fade-in-anim { from { opacity: 0; } to { opacity: 1; } }
        .active .pop-in { animation: pop-in-anim 0.6s ease-out forwards; opacity: 0; transform: scale(0.5); }
        @keyframes pop-in-anim { to { opacity: 1; transform: scale(1); } }
        .active .draw-line { animation: draw-line-anim 1s ease-out forwards; transform-origin: left; transform: scaleX(0); }
        @keyframes draw-line-anim { to { transform: scaleX(1); } }
        
        /* --- DIAPOSITIVA 2 --- */
        .active .neuron-flow > * { animation: fade-in-up-anim 0.5s ease-out forwards; opacity: 0; }
        
        /* --- DIAPOSITIVA 3 --- */
        .active .backprop-arrow { opacity: 0; animation: backprop-flow 0.8s ease-in-out forwards; }
        @keyframes backprop-flow { 
            from { opacity: 0; transform: translateY(-20px); } 
            to { opacity: 1; transform: translateY(0); }
        }
        .active .backprop-layer { opacity: 0; transform: scale(0.8); animation: pop-in-anim 0.6s ease-out forwards; }

        /* --- DIAPOSITIVA 4 --- */
        .active .dropout-neuron { animation: dropout-flicker 2s infinite ease-in-out; }
        @keyframes dropout-flicker {
            0%, 100% { opacity: 1; color: #a78bfa; }
            50% { opacity: 0.2; color: #6b7280; }
        }

        /* --- DIAPOSITIVA 5 --- */
        .active .cnn-filter {
            position: absolute; top: 0; left: 0;
            width: 33.33%; height: 33.33%;
            border: 3px solid #fde047;
            background: rgba(253, 224, 71, 0.2);
            animation: cnn-scan 4s 1s infinite steps(2, end);
        }
        @keyframes cnn-scan {
            0% { transform: translate(0, 0); } 12.5% { transform: translate(100%, 0); } 25% { transform: translate(200%, 0); }
            37.5% { transform: translate(200%, 100%); } 50% { transform: translate(100%, 100%); } 62.5% { transform: translate(0, 100%); }
            75% { transform: translate(0, 200%); } 87.5% { transform: translate(100%, 200%); } 100% { transform: translate(200%, 200%); }
        }
        .active .rnn-loop { animation: rnn-flow 3s 1s linear infinite; }
        @keyframes rnn-flow {
            from { stroke-dashoffset: 1000; } to { stroke-dashoffset: 0; }
        }

        /* --- DIAPOSITIVA 6 --- */
        .active .attention-line { opacity: 0; animation: draw-attention 1.5s ease-out forwards; }
        @keyframes draw-attention {
            from { transform: scale(0); opacity: 0; }
            to { transform: scale(1); opacity: 1; }
        }
        
        #audio-player { position: fixed; bottom: 15px; left:20%; transform: translateX(-50%); width: 80%; max-width: 500px; z-index: 1000; opacity: 0.85; transition: opacity 0.3s; }
        #audio-player:hover { opacity: 1; }
    </style>
</head>
<body>

    <div class="main-view">
        <div class="presentation-wrapper">

            <!-- ===== DIAPOSITIVA 1: Introducción a Deep Learning ===== -->
            <div class="slide active">
                <div class="stars"></div>
                <div class="text-center">
                    <div class="fade-in-up">
                        <h2 class="subtitle text-4xl text-purple-300">Módulo Dos: Deep Learning</h2>
                        <h1 class="title text-6xl mt-2 text-white">El Nivel de Maestría del Machine Learning</h1>
                    </div>
                    <div class="mt-16 w-full max-w-4xl flex justify-center items-center gap-8">
                        <div class="text-center pop-in" style="animation-delay: 0.5s;">
                            <i class="fas fa-brain text-8xl text-pink-400"></i>
                            <p class="mt-4 text-xl">Inspiración Biológica</p>
                        </div>
                        <i class="fas fa-arrow-right text-6xl text-gray-400 pop-in" style="animation-delay: 0.8s;"></i>
                        <div class="text-center pop-in" style="animation-delay: 1.1s;">
                            <div class="flex flex-col gap-2">
                                <div class="w-24 h-4 bg-purple-400 rounded-full"></div>
                                <div class="w-24 h-4 bg-purple-500 rounded-full ml-2"></div>
                                <div class="w-24 h-4 bg-purple-600 rounded-full"></div>
                            </div>
                            <p class="mt-4 text-xl">Jerarquías de Conocimiento</p>
                        </div>
                    </div>
                    <div class="mt-16 content-box rounded-lg p-6 max-w-5xl text-center fade-in" style="animation-delay: 1.5s;">
                        <p class="text-xl">Construimos modelos con cientos de capas de "neuronas" artificiales, capaces de aprender patrones y conceptos increíblemente abstractos, de forma similar a nuestro cerebro.</p>
                    </div>
                </div>
                <div class="footer-note">1 / 6<br>Introducción al Deep Learning</div>
            </div>

            <!-- ===== DIAPOSITIVA 2: La Neurona y la Activación ===== -->
            <div class="slide">
                <div class="stars"></div>
                <div class="w-full max-w-6xl text-center">
                    <h1 class="title text-5xl mb-12 fade-in-up">El Bloque Fundamental: La Neurona Artificial</h1>
                    <div class="grid grid-cols-2 gap-12 items-center">
                        <div class="content-box rounded-xl p-8">
                            <h3 class="subtitle text-3xl text-amber-300 mb-6 fade-in" style="animation-delay: 0.4s;">Perceptrón Multicapa</h3>
                            <div class="flex items-center justify-center gap-4 neuron-flow">
                                <div class="flex flex-col gap-4" style="animation-delay: 0.6s;">
                                    <p>Entradas</p>
                                    <i class="fas fa-arrow-down text-3xl"></i>
                                    <i class="fas fa-circle text-blue-300"></i>
                                    <i class="fas fa-circle text-blue-300"></i>
                                    <i class="fas fa-circle text-blue-300"></i>
                                </div>
                                <i class="fas fa-arrow-right text-4xl text-gray-400" style="animation-delay: 0.8s;"></i>
                                <div class="flex flex-col gap-2 items-center text-center" style="animation-delay: 1.0s;">
                                    <i class="fas fa-plus-circle text-5xl text-green-300"></i>
                                    <p class="mt-2">Suma<br>Ponderada</p>
                                </div>
                                <i class="fas fa-arrow-right text-4xl text-gray-400" style="animation-delay: 1.2s;"></i>
                                <div class="flex flex-col gap-2 items-center text-center" style="animation-delay: 1.4s;">
                                    <i class="fas fa-bolt text-5xl text-yellow-300"></i>
                                    <p class="mt-2">Función de<br>Activación</p>
                                </div>
                                <i class="fas fa-arrow-right text-4xl text-gray-400" style="animation-delay: 1.6s;"></i>
                                <div class="flex flex-col gap-2 items-center" style="animation-delay: 1.8s;">
                                    <p>Salida</p>
                                    <i class="fas fa-arrow-down text-3xl"></i>
                                    <i class="fas fa-check-circle text-xl text-purple-300"></i>
                                </div>
                            </div>
                        </div>
                        <div class="text-left space-y-6">
                             <h3 class="subtitle text-3xl text-purple-300 mb-6 fade-in-up" style="animation-delay: 2.0s;">La Clave: Activación No Lineal</h3>
                             <p class="text-xl fade-in-up" style="animation-delay: 2.2s;">La función de activación decide si una señal es importante y debe pasar a la siguiente capa. Esto introduce la <span class="font-bold text-yellow-300">no linealidad</span>, permitiendo aprender patrones complejos.</p>
                             <div class="content-box rounded-lg p-4 fade-in-up" style="animation-delay: 2.4s;">
                                <h4 class="font-bold text-xl text-yellow-300"><i class="fas fa-chart-line mr-2"></i> ReLU (Unidad Lineal Rectificada)</h4>
                                <p>La preferida en redes modernas: es simple y computacionalmente muy eficiente.</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="footer-note">2 / 6<br>La Neurona y la Activación</div>
            </div>

            <!-- ===== DIAPOSITIVA 3: Backpropagation ===== -->
            <div class="slide">
                <div class="stars"></div>
                <div class="w-full max-w-6xl text-center">
                    <h1 class="title text-5xl mb-4 fade-in-up">El Motor del Aprendizaje: Backpropagation</h1>
                    <h2 class="subtitle text-3xl text-red-300 mb-12 fade-in-up" style="animation-delay: 0.2s;">(El Proceso de Rendición de Cuentas)</h2>
                    
                    <div class="flex justify-around items-center text-center w-full">
                        <!-- Capa de Salida -->
                        <div class="backprop-layer" style="animation-delay: 0.5s;">
                            <i class="fas fa-bullseye text-6xl text-red-400"></i>
                            <h3 class="subtitle text-xl mt-2">Error Final<br>(Capa de Salida)</h3>
                        </div>

                        <i class="fas fa-arrow-left text-5xl text-red-400 backprop-arrow" style="animation-delay: 1.0s;"></i>
                        
                        <!-- Capa Oculta -->
                        <div class="backprop-layer" style="animation-delay: 1.5s;">
                            <div class="grid grid-cols-2 gap-4">
                               <i class="fas fa-user-secret text-5xl text-purple-400"></i>
                               <i class="fas fa-user-secret text-5xl text-purple-400"></i>
                            </div>
                            <h3 class="subtitle text-xl mt-2">Asignar Error<br>(Capas Ocultas)</h3>
                        </div>

                        <i class="fas fa-arrow-left text-5xl text-red-400 backprop-arrow" style="animation-delay: 2.0s;"></i>

                        <!-- Capa de Entrada -->
                        <div class="backprop-layer" style="animation-delay: 2.5s;">
                            <div class="grid grid-cols-2 gap-4">
                                <i class="fas fa-cogs text-5xl text-blue-400"></i>
                                <i class="fas fa-cogs text-5xl text-blue-400"></i>
                            </div>
                            <h3 class="subtitle text-xl mt-2">Ajustar Pesos<br>(Capas Iniciales)</h3>
                        </div>
                    </div>
                     <p class="mt-16 text-2xl max-w-5xl mx-auto fade-in-up" style="animation-delay: 3.0s;">
                        El error se calcula al final y se propaga <span class="text-red-300 font-bold">hacia atrás</span>, capa por capa, indicando a cada neurona cómo debe ajustar sus pesos para mejorar la predicción global.
                    </p>
                </div>
                <div class="footer-note">3 / 6<br>Backpropagation</div>
            </div>

            <!-- ===== DIAPOSITIVA 4: Overfitting y Dropout ===== -->
            <div class="slide">
                <div class="stars"></div>
                 <div class="text-center w-full max-w-6xl">
                    <h1 class="title text-5xl mb-12 fade-in-up">Desafío: Sobreajuste y la Solución: Dropout</h1>
                     <div class="grid grid-cols-2 gap-12 items-center">
                         <div class="content-box rounded-xl p-8 text-center fade-in-up" style="animation-delay: 0.5s;">
                            <h3 class="subtitle text-3xl text-red-400 mb-6">Sobreajuste</h3>
                            <div class="grid grid-cols-4 gap-4 text-purple-400 text-3xl">
                                <i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i>
                                <i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i>
                                <i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i>
                            </div>
                            <p class="mt-6 text-xl">La red "memoriza" los datos de entrenamiento en lugar de aprender el patrón general. Se vuelve demasiado dependiente de neuronas específicas.</p>
                         </div>
                         <div class="content-box rounded-xl p-8 text-center fade-in-up" style="animation-delay: 1.0s;">
                             <h3 class="subtitle text-3xl text-green-400 mb-6">Regularización con Dropout</h3>
                             <div class="grid grid-cols-4 gap-4 text-3xl">
                                <i class="fas fa-brain dropout-neuron" style="animation-delay: 0s;"></i><i class="fas fa-brain"></i><i class="fas fa-brain dropout-neuron" style="animation-delay: 0.5s;"></i><i class="fas fa-brain"></i>
                                <i class="fas fa-brain"></i><i class="fas fa-brain dropout-neuron" style="animation-delay: 1s;"></i><i class="fas fa-brain"></i><i class="fas fa-brain dropout-neuron" style="animation-delay: 0.2s;"></i>
                                <i class="fas fa-brain dropout-neuron" style="animation-delay: 0.8s;"></i><i class="fas fa-brain"></i><i class="fas fa-brain"></i><i class="fas fa-brain dropout-neuron" style="animation-delay: 1.2s;"></i>
                            </div>
                            <p class="mt-6 text-xl">"Apaga" neuronas al azar durante el entrenamiento. Esto fuerza a la red a aprender representaciones más robustas y a no depender de ninguna neurona individual.</p>
                         </div>
                     </div>
                     <div class="fade-in mt-12 text-2xl max-w-5xl mx-auto flex items-center justify-center gap-6" style="animation-delay: 1.8s;">
                        <i class="fas fa-basketball-ball text-5xl text-yellow-300"></i>
                        <p>Como un equipo de baloncesto entrenando con jugadores en el banquillo al azar para no depender de sus estrellas.</p>
                    </div>
                </div>
                <div class="footer-note">4 / 6<br>Regularización y Dropout</div>
            </div>

            <!-- ===== DIAPOSITIVA 5: Arquitecturas Especializadas ===== -->
            <div class="slide">
                <div class="stars"></div>
                <div class="w-full max-w-6xl">
                    <h1 class="title text-5xl mb-12 text-center fade-in-up">Arquitecturas Especializadas</h1>
                    <div class="grid grid-cols-2 gap-10">
                        <!-- Columna CNN -->
                        <div class="content-box rounded-xl p-8 fade-in-up" style="animation-delay: 0.4s;">
                            <div class="flex items-center gap-4 mb-4">
                                <i class="fas fa-camera-retro text-5xl text-cyan-300"></i>
                                <h3 class="title text-3xl">Redes Convolucionales (CNN)</h3>
                            </div>
                            <p class="text-lg mb-6">Las reinas de la <span class="font-bold text-cyan-300">visión por computador</span>. Usan "filtros" que buscan patrones locales (bordes, texturas) de forma jerárquica.</p>
                            <div class="relative w-48 h-48 grid grid-cols-3 grid-rows-3 gap-1 mx-auto bg-gray-800 p-1 rounded">
                                <div class="bg-gray-700"></div><div class="bg-gray-200"></div><div class="bg-gray-700"></div>
                                <div class="bg-gray-200"></div><div class="bg-gray-200"></div><div class="bg-gray-200"></div>
                                <div class="bg-gray-700"></div><div class="bg-gray-200"></div><div class="bg-gray-700"></div>
                                <div class="cnn-filter"></div>
                            </div>
                        </div>
                        <!-- Columna RNN -->
                        <div class="content-box rounded-xl p-8 fade-in-up" style="animation-delay: 0.8s;">
                             <div class="flex items-center gap-4 mb-4">
                                <i class="fas fa-stream text-5xl text-lime-300"></i>
                                <h3 class="title text-3xl">Redes Recurrentes (RNN/LSTM)</h3>
                            </div>
                            <p class="text-lg mb-6">Para datos <span class="font-bold text-lime-300">secuenciales</span> (texto, series temporales). Tienen una "memoria" que retiene información de pasos anteriores.</p>
                            <div class="flex justify-around items-center w-full h-48 relative">
                               <div class="pop-in" style="animation-delay: 1.2s;"><i class="fas fa-square text-3xl text-blue-300"></i></div>
                               <div class="pop-in" style="animation-delay: 1.5s;"><i class="fas fa-square text-3xl text-blue-300"></i></div>
                               <div class="pop-in" style="animation-delay: 1.8s;"><i class="fas fa-square text-3xl text-blue-300"></i></div>
                               <svg class="absolute w-4/5 h-full" viewbox="0 0 200 100" preserveAspectRatio="none">
                                 <path d="M 30 50 C 30 20, 70 20, 70 50 S 110 80, 110 50 S 150 20, 150 50" stroke="#fde047" stroke-width="4" fill="none" stroke-dasharray="1000" class="rnn-loop"/>
                               </svg>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="footer-note">5 / 6<br>Arquitecturas Clásicas</div>
            </div>

            <!-- ===== DIAPOSITIVA 6: Transformers y el Futuro Colaborativo ===== -->
            <div class="slide">
                <div class="stars"></div>
                <div class="text-center w-full max-w-6xl">
                    <h1 class="title text-5xl mb-4 fade-in-up">La Revolución: Transformers y Colaboración</h1>
                    <h2 class="subtitle text-3xl text-cyan-300 mb-12 fade-in-up" style="animation-delay: 0.2s;">El poder del Mecanismo de Atención y el Código Abierto</h2>
                    <div class="flex justify-between items-center w-full">
                        <div class="flex flex-col items-center gap-4">
                            <i class="fas fa-file-alt text-6xl text-purple-300 pop-in" style="animation-delay: 0.6s;"></i>
                            <p class="font-bold">Texto</p>
                        </div>
                        <div class="flex flex-col items-center gap-4">
                            <i class="fas fa-image text-6xl text-green-300 pop-in" style="animation-delay: 0.8s;"></i>
                            <p class="font-bold">Imagen</p>
                        </div>
                        
                        <div class="relative flex flex-col items-center">
                            <div class="w-1 h-20 bg-gray-500 attention-line" style="transform-origin: bottom; animation-delay: 1.2s;"></div>
                             <div class="w-20 h-1 bg-gray-500 absolute top-1/2 -left-20 attention-line" style="transform-origin: right; animation-delay: 1.4s;"></div>
                             <div class="w-20 h-1 bg-gray-500 absolute top-1/2 -right-20 attention-line" style="transform-origin: left; animation-delay: 1.4s;"></div>
                            <i class="fas fa-robot text-8xl text-cyan-300 pop-in" style="animation-delay: 1.0s; z-index: 10;"></i>
                            <h3 class="subtitle text-2xl mt-4">Transformer</h3>
                        </div>

                        <div class="flex flex-col items-center gap-4">
                            <i class="fas fa-volume-up text-6xl text-yellow-300 pop-in" style="animation-delay: 0.9s;"></i>
                             <p class="font-bold">Audio</p>
                        </div>
                        <div class="flex flex-col items-center gap-4">
                            <i class="fas fa-code text-6xl text-red-300 pop-in" style="animation-delay: 0.7s;"></i>
                            <p class="font-bold">Código</p>
                        </div>
                    </div>
                    <div class="content-box rounded-xl p-8 mt-16 max-w-5xl mx-auto fade-in" style="animation-delay: 2.0s;">
                        <h3 class="subtitle text-2xl mb-4 text-cyan-300">Un Ecosistema Abierto y Colaborativo</h3>
                        <div class="flex justify-around items-center text-4xl">
                            <i class="fab fa-hugging-face text-yellow-300" title="Hugging Face"></i>
                            <i class="fab fa-github" title="GitHub"></i>
                            <i class="fas fa-users text-purple-300" title="Comunidad"></i>
                            <p class="font-bold text-2xl">Open Assistant</p>
                        </div>
                        <p class="mt-4 text-lg">Plataformas como Hugging Face y proyectos como Open Assistant ponen modelos de última generación al alcance de todos, invitándonos a colaborar en la creación del futuro de la IA.</p>
                    </div>
                </div>
                <div class="footer-note">6 / 6<br>Transformers y Futuro</div>
            </div>

        </div>

        <div id="script-panel">
            <!-- El guion se cargará aquí -->
        </div>
    </div>

    <!-- ===== CONTROLES DE NAVEGACIÓN Y AUDIO ===== -->
    <div id="navigation-controls">
        <button id="prev-btn" title="Anterior"><i class="fas fa-arrow-left"></i></button>
        <span id="slide-counter">1 / 6</span>
        <button id="next-btn" title="Siguiente"><i class="fas fa-arrow-right"></i></button>
    </div>
    <audio id="audio-player" controls>
        <source src="3.wav" type="audio/wav">
        Tu navegador no soporta el elemento de audio.
    </audio>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const slides = document.querySelectorAll('.slide');
            const prevBtn = document.getElementById('prev-btn');
            const nextBtn = document.getElementById('next-btn');
            const counterElement = document.getElementById('slide-counter');
            const scriptPanel = document.getElementById('script-panel');
            let currentSlide = 0;

            const scriptsBySlide = [
                {
                    "title": "DIAPOSITIVA 1: Introducción a Deep Learning",
                    "script": "Módulo Dos. Si el Machine Learning es el arte de enseñar a las máquinas a partir de datos, el Aprendizaje Profundo o Deep Learning es el nivel de maestría, donde llevamos esa enseñanza a una escala y complejidad que se asemeja, aunque sea de forma muy simplificada, al funcionamiento de nuestro propio cerebro. Ya no hablamos de algoritmos que aprenden una simple relación lineal; hablamos de construir modelos con docenas o incluso cientos de capas de \"neuronas\" artificiales, capaces de aprender jerarquías de conocimiento increíblemente abstractas."
                },
                {
                    "title": "DIAPOSITIVA 2: El Bloque Fundamental: La Neurona",
                    "script": "Todo comienza con una inspiración biológica: la neurona. En los años cincuenta, se creó el primer modelo matemático de una neurona, el Perceptrón. Era una unidad muy simple: recibía varias entradas numéricas, las sumaba ponderadamente y, si el resultado superaba un cierto umbral, se \"activaba\" y emitía una salida. La verdadera magia ocurre cuando conectamos muchos de estos perceptrones en capas, creando un Perceptrón Multicapa. ... Para que esta red pueda aprender algo más complejo que una línea recta, cada neurona necesita una unidad de activación no lineal. No se trata solo de sumar y pasar el resultado; la función de activación decide qué tan importante es esa señal, introduciendo la no linealidad que permite al modelo aprender patrones complejos. Las redes modernas prefieren abrumadoramente la ReLU (Unidad Lineal Rectificada), que es computacionalmente mucho más eficiente."
                },
                {
                    "title": "DIAPOSITIVA 3: El Motor del Aprendizaje: Backpropagation",
                    "script": "Ahora, ¿cómo aprende esta red? Exactamente igual que en el machine learning clásico: midiendo su error y tratando de minimizarlo. Usamos una función de coste para medir el error y el Descenso de Gradiente para ajustar los parámetros. ... Pero con tantas capas, ¿cómo sabe una neurona al principio de la red si su ajuste fue bueno o malo? La respuesta es el algoritmo de Backpropagation. ... Imaginen una gran corporación donde un proyecto falla. Backpropagation es como el proceso de rendición de cuentas. El director (capa de salida) calcula el error total. Luego, se reúne con los gerentes (capa anterior) y les asigna su parte de responsabilidad. Este proceso se repite hacia atrás, capa por capa, hasta llegar a los empleados iniciales. Cada neurona recibe una señal clara sobre cuánto contribuyó al error final y en qué dirección debe ajustar sus pesos."
                },
                {
                    "title": "DIAPOSITIVA 4: Desafíos del Entrenamiento",
                    "script": "Entrenar una red con millones de parámetros es un desafío. Primero, la inicialización de los parámetros es crucial para dar un buen punto de partida. Segundo, las redes profundas son extremadamente propensas al sobreajuste. Pueden \"memorizar\" los datos de entrenamiento en lugar de aprender el patrón general. Para combatir esto, usamos técnicas de regularización. ... La más popular es el Dropout. Imaginen que están entrenando a un equipo de baloncesto. Si siempre juegan con los mismos cinco jugadores estrella, el equipo se volverá muy dependiente de ellos. El Dropout hace lo siguiente: en cada jugada del entrenamiento, obliga a algunos jugadores a sentarse en el banquillo al azar. Esto fuerza a que todos aprendan a jugar bien con diferentes compañeros. En una red neuronal, el Dropout apaga aleatoriamente un porcentaje de neuronas durante cada paso del entrenamiento, lo que obliga a la red a aprender representaciones más robustas."
                },
                {
                    "title": "DIAPOSITIVA 5: Arquitecturas Especializadas",
                    "script": "No hay una única arquitectura de red neuronal. Dependiendo del problema, usamos diseños especializados. ... La primera gran arquitectura son las Redes Neuronales Convolucionales, o CNNs, las reinas de la visión por computador. Utilizan \"filtros\" que se deslizan a través de una imagen, buscando patrones locales como bordes o texturas de forma jerárquica. ... Para datos que tienen una secuencia, como el texto o series temporales, usamos las Redes Neuronales Recurrentes, o RNNs. Su característica clave es que tienen un \"bucle\", una forma de memoria. Cuando procesan una palabra, tienen en cuenta las palabras que han visto antes. Arquitecturas mejoradas como las LSTM y las GRU utilizan \"compuertas\" para decidir qué información guardar en la memoria a largo plazo y qué olvidar."
                },
                {
                    "title": "DIAPOSITIVA 6: La Revolución: Transformers y Colaboración",
                    "script": "La verdadera revolución de la última década ha sido la invención de los Mecanismos de Atención y la arquitectura Transformer. Las RNNs intentan comprimir el significado de toda una frase en un único vector de \"memoria\", lo cual es un cuello de botella. Los Transformers solucionaron esto con el mecanismo de atención. Le permite \"mirar\" y ponderar la importancia de cada una de las palabras de la frase original al generar cada nueva palabra. Esta es la arquitectura que impulsa a modelos como GPT-4. ... Finalmente, lo más emocionante es que todo este poder ya no está reservado a los gigantes tecnológicos. Plataformas como Hugging Face se han convertido en el \"GitHub\" del machine learning, donde se comparten miles de modelos pre-entrenados. Proyectos como Open Assistant demuestran el poder de la comunidad para construir IA transparente y accesible para todos. Como ingenieros, las herramientas para construir el futuro están a nuestro alcance."
                }
            ];

            function showSlide(index) {
                if (slides[currentSlide]) {
                    slides[currentSlide].classList.remove('active');
                }
                currentSlide = index;
                if (slides[currentSlide]) {
                    slides[currentSlide].classList.add('active');
                }
                counterElement.textContent = `${currentSlide + 1} / ${slides.length}`;
                prevBtn.disabled = (currentSlide === 0);
                nextBtn.disabled = (currentSlide === slides.length - 1);
                
                if (scriptPanel && scriptsBySlide[index]) {
                    const { title, script } = scriptsBySlide[index];
                    const scriptParagraphs = script.split('...').map(p => p.replace(/\n/g, ' ').trim()).filter(Boolean);
                    
                    let htmlContent = `<h2>${title}</h2>`;
                    htmlContent += `<h3>Guion</h3>`;
                    scriptParagraphs.forEach(p => {
                        htmlContent += `<p>${p}</p>`;
                    });

                    scriptPanel.innerHTML = htmlContent;
                }
            }

            prevBtn.addEventListener('click', () => {
                if (currentSlide > 0) {
                    showSlide(currentSlide - 1);
                }
            });

            nextBtn.addEventListener('click', () => {
                if (currentSlide < slides.length - 1) {
                    showSlide(currentSlide + 1);
                }
            });

            document.addEventListener('keydown', (e) => {
                if (e.key === 'ArrowRight' && !nextBtn.disabled) {
                    nextBtn.click();
                } else if (e.key === 'ArrowLeft' && !prevBtn.disabled) {
                    prevBtn.click();
                }
            });

            showSlide(0);
        });
    </script>
</body>
</html>