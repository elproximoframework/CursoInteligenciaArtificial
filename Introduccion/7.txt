Módulo Seis. Hemos explorado la IA que aprende de datos etiquetados y la que encuentra patrones en el caos. Hemos visto cómo puede entender el lenguaje y la visión, e incluso cómo puede generar creaciones nuevas. Pero ahora, vamos a adentrarnos en los paradigmas que están en la frontera, aquellos que enseñan a la IA no solo a analizar, sino a actuar, a colaborar de forma segura y a interactuar con el mundo físico.

En primer lugar, tenemos el Aprendizaje por Refuerzo. A diferencia del aprendizaje supervisado, aquí no hay un profesor que le da a la IA todas las respuestas correctas. En cambio, es como entrenar a un cachorro para que aprenda un truco nuevo. Hay cuatro elementos clave en este proceso. Primero, tenemos al Agente, que es nuestro cachorro, la IA que toma las decisiones. Segundo, está el Entorno, que es la habitación donde lo estamos entrenando. Tercero, están las Acciones que el agente puede realizar, como sentarse, dar la pata o ladrar. Y cuarto, y lo más importante, está la Recompensa, el premio que le damos cuando hace algo bien. El objetivo del agente no es aprender a hacer una acción específica, sino descubrir por sí mismo una estrategia, que llamamos Política, para actuar de la manera que maximice la cantidad de premios que recibe a lo largo del tiempo.

Este proceso de ensayo y error se formaliza matemáticamente a través de los Procesos de Decisión de Markov o MDPs, que son un marco para describir este juego entre el agente y el entorno. Y el santo grial dentro de este marco son las Ecuaciones de Bellman. Estas ecuaciones son, en esencia, una forma de expresar una idea muy intuitiva: el valor de estar en una situación determinada es igual a la recompensa inmediata que obtienes, más el valor de la mejor situación a la que puedes llegar desde aquí. Es un principio de optimismo recursivo. Para nuestro cachorro, el valor de estar sentado frente a ti con una galleta en la mano es muy alto, porque la recompensa inmediata es obvia y el futuro es prometedor.

Pero, ¿cómo aprende el agente este "valor"? Aquí entran los algoritmos. El más clásico es el Q-Learning. En lugar de resolver las ecuaciones de Bellman directamente, el Q-Learning las aprende por exploración. El agente prueba acciones al azar, observa las recompensas y poco a poco construye una "tabla de valores" interna que le dice qué tan buena es cada acción en cada situación. Cuando esta idea se combina con redes neuronales profundas para manejar entornos increíblemente complejos, como un videojuego de Atari o el juego del Go, obtenemos las Deep Q-Networks o DQN. Y para entornos aún más complejos, como enseñar a un robot a caminar, usamos métodos de gradiente de políticas como PPO, que aprenden directamente la política óptima en lugar de los valores de las acciones, a menudo resultando más estables y eficientes.

Ahora, cambiemos de tercio. ¿Qué ocurre cuando el desafío no es aprender de la interacción, sino aprender de datos que no podemos ver, datos que son privados y no pueden salir de su ubicación original? Aquí es donde entra en juego el segundo paradigma avanzado: el Aprendizaje Federado.

Imaginen que varios hospitales quieren colaborar para entrenar un modelo de IA que detecte una enfermedad rara en imágenes médicas. El problema es que, por leyes de privacidad, no pueden compartir los datos de sus pacientes. El enfoque tradicional de juntar todos los datos en un servidor central es imposible. El aprendizaje federado resuelve este problema con una idea brillante: si los datos no pueden ir al modelo, entonces el modelo debe ir a los datos. El proceso funciona así: en primer lugar, un servidor central inicializa un modelo global y lo envía a cada uno de los hospitales. En segundo lugar, cada hospital entrena su copia del modelo utilizando únicamente sus datos locales y privados. Los datos de los pacientes nunca abandonan el hospital. En tercer lugar, en lugar de enviar los datos, cada hospital envía de vuelta al servidor central únicamente las actualizaciones, los "aprendizajes" que su modelo ha adquirido. Finalmente, el servidor central promedia estas actualizaciones de todos los hospitales para crear una nueva versión mejorada del modelo global, y el ciclo se repite.

Es un sistema de aprendizaje distribuido y colaborativo que preserva la privacidad por diseño. Existen diferentes arquitecturas, como la horizontal, donde todos tienen el mismo tipo de datos, o la vertical, para cuando diferentes organizaciones tienen distintas piezas de información sobre los mismos usuarios. Pero para que este sistema sea verdaderamente seguro, a menudo se le añade una capa extra de protección llamada Privacidad Diferencial. Consiste en añadir una pequeña cantidad de ruido matemático a las actualizaciones que se envían al servidor. Este ruido es lo suficientemente pequeño como para no afectar el rendimiento general del modelo agregado, pero lo suficientemente grande como para hacer matemáticamente imposible que alguien pueda realizar ingeniería inversa sobre esas actualizaciones para intentar averiguar información sobre un paciente individual.

Hemos visto una IA que actúa y una IA que aprende de forma privada. El tercer y último paradigma es donde todo converge: la Robótica y la Automatización, el punto en el que la IA se encuentra con el mundo físico. Un robot no es solo un programa; es un sistema integrado. Sus componentes clave son, en primer lugar, los sensores —cámaras, micrófonos, sensores táctiles— que son sus sentidos para percibir el entorno. En segundo lugar, los actuadores —motores, pinzas, ruedas— que son sus músculos para moverse e interactuar con el mundo. Y en tercer lugar, y más importante, su controlador, que es su cerebro, donde reside la IA.

Aquí es donde todas las especialidades que hemos visto se unen en una sinfonía. La Visión por Computador le permite al robot ver y reconocer objetos. El Procesamiento del Lenguaje Natural le permite entender nuestras órdenes de voz. Y el Aprendizaje por Refuerzo es a menudo la técnica utilizada para enseñarle tareas complejas de manipulación o navegación, permitiéndole aprender a caminar o a coger un objeto por ensayo y error en un entorno simulado antes de transferir ese conocimiento al robot físico.

Pero el concepto de "robot" se ha expandido más allá de lo físico. También tenemos robots de software, y aquí es donde entra la Automatización de Procesos o RPA. En su forma más básica, la RPA es el uso de bots para automatizar tareas digitales repetitivas y basadas en reglas: copiar datos de un correo electrónico y pegarlos en una hoja de cálculo, rellenar formularios, iniciar sesión en sistemas... Pero la verdadera revolución está ocurriendo ahora, al integrar la IA en estos procesos. En lugar de un bot que solo sigue reglas, ahora tenemos un bot que puede usar una API para llamar a un modelo de lenguaje y entender el sentimiento de un correo de un cliente, o usar visión por computador para extraer información de una factura escaneada. Esto transforma la RPA en automatización inteligente, permitiendo automatizar flujos de trabajo mucho más complejos y cognitivos. Estos paradigmas avanzados no son solo extensiones de lo que ya sabemos; representan un cambio fundamental en cómo concebimos y construimos sistemas inteligentes, llevándonos un paso más cerca de una IA que puede aprender, razonar y actuar de forma verdaderamente autónoma y segura en nuestro mundo.